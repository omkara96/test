from datetime import datetime
from airflow import DAG
from airflow.operators.dagrun_operator import TriggerDagRunOperator
from airflow.operators.python_operator import PythonOperator

# Define the list of dictionaries containing the parameters
parameter_list = [
    {"param1": "value1", "param2": "value2"},
    {"param1": "value3", "param2": "value4"},
    # Add more dictionaries as needed
]

# Define the main DAG
default_args = {
    'start_date': datetime(2023, 1, 1),
    'catchup': False,
}

dag = DAG('dynamic_dag', default_args=default_args, schedule_interval=None)


def monitor_task(**kwargs):
    execution_dates = kwargs['ti'].xcom_pull(task_ids=[f'trigger_task_{i+1}' for i in range(len(parameter_list))])
    for i, execution_date in enumerate(execution_dates):
        print(f'Task {i+1} completed at: {execution_date}')


# Create tasks dynamically based on the parameter list
for i, parameters in enumerate(parameter_list):
    task_id = f'task_{i+1}'
    trigger_task_id = f'trigger_task_{i+1}'

    trigger_task = TriggerDagRunOperator(
        task_id=trigger_task_id,
        trigger_dag_id='existing_dag_id',  # Specify the ID of the existing DAG you want to trigger
        conf=parameters,  # Pass the parameters as configuration to the triggered DAG
        dag=dag,
    )

    monitor_task >> trigger_task


def print_success_message(**kwargs):
    execution_dates = kwargs['ti'].xcom_pull(task_ids=[f'trigger_task_{i+1}' for i in range(len(parameter_list))])
    print("All tasks completed successfully!")
    for i, execution_date in enumerate(execution_dates):
        print(f"Task {i+1} completed at: {execution_date}")


success_task = PythonOperator(
    task_id='success_task',
    python_callable=print_success_message,
    provide_context=True,
    dag=dag,
)

for i, _ in enumerate(parameter_list):
    task_id = f'trigger_task_{i+1}'
    monitor_task.set_upstream(dag.get_task(task_id))

monitor_task.set_downstream(success_task)

