def check_file_existence(src_bucket, from_s3_prefix, arn_role, file_pattern, most_recent_only, target_file_nm,
                         target_file_extnsn, to_s3_prefix, dest_bucket, area_cd, source_system):
    s3_client = _get_s3_client(arn_role)

    paginator = s3_client.get_paginator('list_objects_v2')
    response_iterator = paginator.paginate(Bucket=src_bucket, Prefix=from_s3_prefix)

    files = []
    for response in response_iterator:
        if 'Contents' in response:
            for obj in response['Contents']:
                files.append(obj['Key'])

    regex_pattern = file_pattern.replace('*', '.*')  # Convert * to .* for regular expression matching
    filtered_list = [file for file in files if re.match(regex_pattern, file)]

    if not filtered_list:
        send_email_notification("No file exists that matches the condition")
        return

    if most_recent_only:
        most_recent_file = max(filtered_list, key=lambda file_name: s3_client.head_object(Bucket=src_bucket,
                                                                                           Key=file_name)['LastModified'])
        source_key = most_recent_file
    else:
        # Add your logic here to select the file(s) you want to copy if not just the most recent one
        # For example, you can choose the first file in the filtered_list
        source_key = filtered_list[0]

    target_key = f"{to_s3_prefix}/{target_file_nm}{today}{target_file_extnsn}"

    try:
        s3_client.copy_object(CopySource={'Bucket': src_bucket, 'Key': source_key},
                              Bucket=dest_bucket, Key=target_key)
        send_email_notification(f"File '{source_key}' copied successfully as '{target_key}'")
    except Exception as e:
        send_email_notification(f"An exception occurred while copying the file: {str(e)}")
